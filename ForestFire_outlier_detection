{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ForestFire_outlier_detection","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1aGKIJr8HO5i4BsLMloEIpZxoAFJYP2sV","authorship_tag":"ABX9TyMchL2hc/tOO7WeZmFgCg+U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"id":"tE5ZfugDBSzG","executionInfo":{"status":"ok","timestamp":1654172358951,"user_tz":-600,"elapsed":449,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"outputs":[],"source":["# # #  Import libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n","import tensorflow as tf\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.losses import MeanSquaredLogarithmicError\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"EOV9ulze-r4A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654172361672,"user_tz":-600,"elapsed":2331,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}},"outputId":"32b28623-ed60-4ffc-db82-0b07036bf792"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# # #  import data\n","df = pd.read_csv('/content/drive/MyDrive/dataset/forestfires.csv')"],"metadata":{"id":"yvSwLPs4CJO8","executionInfo":{"status":"ok","timestamp":1654172361673,"user_tz":-600,"elapsed":7,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# # #  Parameter configurations\n","SIGMA = 0.5\n","PERCENTAGE_OUTLIER = 6*5\n","OUTLIER_PECENTAGE = 5\n","\n","length = df.shape[0]\n","\n","columns = df.columns.tolist()"],"metadata":{"id":"C-pYWygRCN0z","executionInfo":{"status":"ok","timestamp":1654172361673,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# # # Preprocessing data \n","def day_name_to_num(day_name):\n","    day_list = {'mon':1, 'tue':2, 'wed':3, 'thu':4, 'fri':5, 'sat':6, 'sun':7}\n","    for item, num in day_list.items():\n","        if day_name == item:\n","            return(num)\n","\n","df['month'] = pd.to_datetime(df.month, format='%b').dt.month\n","\n","# Convert day to numerial\n","for i in range(length):\n","    df.loc[i,'day'] = day_name_to_num(df.loc[i, 'day'])\n","\n","# Label the outlier and inlier\n","for i in range(length):\n","    df.loc[i, 'index'] = i\n","    df.loc[i, 'label'] = 1\n","\n","# Select random index for outlier\n","random_indices = np.random.choice(df.index, PERCENTAGE_OUTLIER, replace = False)\n","\n","# Creating outlier data (temperature)\n","\n","for index in random_indices:\n","    df_1 = df.iloc[index]\n","    temp = df_1['temp']\n","\n","    sigma_T = SIGMA * temp\n","    noise_T = random.gauss(0, sigma_T)\n","\n","    temp += noise_T\n","    df_1['temp'] = temp\n","    df_1['label'] = 0\n","\n","    length +=1\n","    df.loc[length] = df_1\n","\n","# # Creating outlier data (humidity)\n","\n","# for index in random_indices:\n","#     df_1 = df.iloc[index]\n","#     Rh = df_1['RH']\n","\n","#     sigma_T = SIGMA * Rh\n","#     noise_T = random.gauss(0, sigma_T)\n","\n","#     Rh += noise_T\n","#     df_1['RH'] = Rh\n","#     df_1['label'] = 0\n","\n","#     length +=1\n","#     df.loc[length] = df_1\n","\n","# Shuffling the dataset\n","#df = df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"8KtywCMfB868","executionInfo":{"status":"ok","timestamp":1654172362327,"user_tz":-600,"elapsed":659,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# # # Splitting the dataset\n","\n","y = df['label']\n","X = df.drop(['index', 'label'], axis =1)\n","\n","# Spliting data\n","x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.3, stratify=y)\n"],"metadata":{"id":"IBwPX9ejDOGN","executionInfo":{"status":"ok","timestamp":1654172362327,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# # Random Forest\n","forest = RandomForestClassifier(n_estimators = 10, random_state = 0)\n","forest.fit(x_train, y_train)\n","preds = forest.predict(x_test)\n","\n","\n","# Metrics\n","print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","print('f1_score: ', round(f1_score(y_test,preds),6))\n","print('precision_score: ', round(precision_score(y_test,preds),6))\n","print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))"],"metadata":{"id":"gC5qz7ugDZAZ","executionInfo":{"status":"ok","timestamp":1654172362327,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89fc0454-a6a9-43e4-8634-5ab12ef81102"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy_score:  92.73\n","f1_score:  0.962025\n","precision_score:  0.95\n","recall_score:  0.974359\n"]}]},{"cell_type":"code","source":["# # # # Deep Neural Network Classifier\n","\n","# x_train = np.asarray(x_train).astype('float32')\n","# x_test = np.asarray(x_test).astype('float32')\n","# y_train = np.asarray(y_train).astype('float32')\n","# y_test = np.asarray(y_test).astype('float32')\n","\n","# # Splitting the for testing and validating dataset\n","# x_val, x_test, y_val, y_test = train_test_split(x_test,y_test, test_size=0.33, stratify=y_test)\n","\n","# # Configurations\n","# output_size = 1\n","# hidden_layer_size = 5\n","\n","# # model\n","\n","# model = tf.keras.Sequential([tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n","#                              tf.keras.layers.Dense(5, activation = 'relu'),\n","#                              tf.keras.layers.Dense(output_size, activation = 'sigmoid')\n","#                             ])\n","\n","# model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n","#               metrics=['accuracy'])\n","\n","\n","# # # simple early stopping\n","# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n","\n","# model.fit(x_train, y_train, batch_size = 64, epochs = 50, shuffle=True,\n","#           validation_data = (x_val, y_val), verbose = 0, callbacks=[es])\n","\n","\n","# # Processing the y_predict\n","# preds = model.predict(x_test)\n","# preds = preds.flatten()\n","# preds = np.where(preds > 0.5, 1, 0)\n","# preds = np.asarray(preds).astype('float32')\n","\n","# # Metrics\n","# print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","# print('f1_score: ', round(f1_score(y_test,preds),6))\n","# print('precision_score: ', round(precision_score(y_test,preds),6))\n","# print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))\n"],"metadata":{"id":"nRQDS9n3EeVe","executionInfo":{"status":"ok","timestamp":1654172362328,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# # # # # Autoencoder\n","\n","# x_train = np.asarray(x_train).astype('float32')\n","# x_test = np.asarray(x_test).astype('float32')\n","# y_train = np.asarray(y_train).astype('float32')\n","# y_test = np.asarray(y_test).astype('float32')\n","\n","# # Splitting the for testing and validating dataset\n","# x_val, x_test, y_val, y_test = train_test_split(x_test,y_test, test_size=0.33,stratify=y_test)\n","\n","# class AutoEncoder(Model):\n","#   \"\"\"\n","#   Parameters\n","#   ----------\n","#   output_units: int\n","#     Number of output units\n","  \n","#   code_size: int\n","#     Number of units in bottle neck\n","#   \"\"\"\n","\n","#   def __init__(self, output_units, code_size=8):\n","#     super().__init__()\n","#     self.encoder = Sequential([\n","#       Dense(64, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(32, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(16, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(code_size, activation='relu')\n","#     ])\n","#     self.decoder = Sequential([\n","#       Dense(16, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(32, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(64, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(output_units, activation='sigmoid')\n","#     ])\n","  \n","#   def call(self, inputs):\n","#     encoded = self.encoder(inputs)\n","#     decoded = self.decoder(encoded)\n","#     return decoded\n","\n","# model = AutoEncoder(output_units=x_train.shape[1])\n","# # configurations of model\n","# model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n","\n","# # simple early stopping\n","# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n","\n","# history = model.fit(\n","#     x_train,\n","#     x_train,\n","#     epochs=50,\n","#     batch_size=128,\n","#     validation_data=(x_val, x_val),\n","#     verbose=0,\n","#     callbacks=[es]\n","# )\n","\n","# def find_threshold(model, x_train_scaled):\n","#   # another method to find threshold\n","#   reconstructions = model.predict(x_train_scaled)\n","#   # provides losses of individual instances\n","#   reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n","\n","#   threshold_2 = np.percentile(reconstruction_errors, 100-OUTLIER_PECENTAGE)\n","#   return threshold_2\n","\n","# def get_predictions(model, x_test_scaled, threshold):\n","#   predictions = model.predict(x_test_scaled)\n","#   # provides losses of individual instances\n","#   errors = tf.keras.losses.msle(predictions, x_test_scaled)\n","#   # 0 = anomaly, 1 = normal\n","#   anomaly_mask = pd.Series(errors) > threshold\n","#   preds = anomaly_mask.map(lambda x: 0.0 if x == True else 1.0)\n","#   return preds\n","\n","# threshold = find_threshold(model, x_train)\n","# preds = get_predictions(model, x_test, threshold)\n","\n","# preds = np.asarray(preds).astype('float32')\n","\n","# # Metrics\n","# print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","# print('f1_score: ', round(f1_score(y_test,preds),6))\n","# print('precision_score: ', round(precision_score(y_test,preds),6))\n","# print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))"],"metadata":{"id":"Xtm95dWZRDt6","executionInfo":{"status":"ok","timestamp":1654172362328,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# # # # KNeighborsClassifier\n","\n","# neigh = KNeighborsClassifier(n_neighbors=5)\n","# neigh.fit(x_train, y_train)\n","\n","# preds = neigh.predict(x_test)\n","\n","# # Metrics\n","# print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","# print('f1_score: ', round(f1_score(y_test,preds),6))\n","# print('precision_score: ', round(precision_score(y_test,preds),6))\n","# print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))"],"metadata":{"id":"zpQ5XskBH3T1","executionInfo":{"status":"ok","timestamp":1654172362328,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":30,"outputs":[]}]}