{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ForestFire_outlier_detection_FID","provenance":[{"file_id":"1aGKIJr8HO5i4BsLMloEIpZxoAFJYP2sV","timestamp":1654143895418}],"collapsed_sections":[],"machine_shape":"hm","toc_visible":true,"mount_file_id":"1aGKIJr8HO5i4BsLMloEIpZxoAFJYP2sV","authorship_tag":"ABX9TyMxP8i9a9nqmK15HbUH6nOA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5075,"metadata":{"id":"tE5ZfugDBSzG","executionInfo":{"status":"ok","timestamp":1655291169088,"user_tz":-600,"elapsed":397,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"outputs":[],"source":["# # #  Import libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n","import tensorflow as tf\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.losses import MeanSquaredLogarithmicError\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"EOV9ulze-r4A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655291172000,"user_tz":-600,"elapsed":2343,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}},"outputId":"fe8f26a0-7dcb-4484-9ac6-4599a49c78bd"},"execution_count":5076,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# # #  import data\n","df = pd.read_csv('/content/drive/MyDrive/dataset/forestfires.csv')"],"metadata":{"id":"yvSwLPs4CJO8","executionInfo":{"status":"ok","timestamp":1655291172001,"user_tz":-600,"elapsed":18,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5077,"outputs":[]},{"cell_type":"code","source":["# # #  Parameter configurations\n","SIGMA = 0.2\n","PERCENTAGE_OUTLIER = 6*8\n","OUTLIER_PECENTAGE = 1\n","PERCENTAGE_REPAIRED = 6*5\n","    \n","length = df.shape[0]\n","\n","columns = df.columns.tolist()\n"],"metadata":{"id":"C-pYWygRCN0z","executionInfo":{"status":"ok","timestamp":1655291172001,"user_tz":-600,"elapsed":17,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5078,"outputs":[]},{"cell_type":"code","source":["# # # Preprocessing data \n","def day_name_to_num(day_name):\n","    day_list = {'mon':1, 'tue':2, 'wed':3, 'thu':4, 'fri':5, 'sat':6, 'sun':7}\n","    for item, num in day_list.items():\n","        if day_name == item:\n","            return(num)\n","\n","df['month'] = pd.to_datetime(df.month, format='%b').dt.month\n","\n","# Convert day to numerial\n","for i in range(length):\n","    df.loc[i,'day'] = day_name_to_num(df.loc[i, 'day'])\n","\n","# Label the outlier and inlier\n","for i in range(length):\n","    df.loc[i, 'index'] = i\n","    df.loc[i, 'label'] = 1\n","\n","# Select random index for outlier\n","random_indices = np.random.choice(df.index, PERCENTAGE_OUTLIER, replace = False)\n","\n","# Creating outlier data (temperature or humidity)\n","for index in random_indices:\n","    df_1 = df.iloc[index]\n","    temp = df_1['RH']\n","\n","    sigma_T = SIGMA * temp\n","    noise_T = random.gauss(0, sigma_T)\n","\n","    temp += noise_T\n","    df_1['RH']  = temp\n","    df_1['label'] = 0\n","\n","    length +=1\n","    df.loc[length] = df_1\n","    # df.loc[index] = df_1\n","\n","# Shuffling the dataset\n","df = df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"8KtywCMfB868","executionInfo":{"status":"ok","timestamp":1655291172995,"user_tz":-600,"elapsed":1010,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5079,"outputs":[]},{"cell_type":"code","source":["# # # FID for repairing data\n","def FID_repaired(working_list):\n","    # working_list = x1\n","    \n","    index = []\n","    for i, j in enumerate(working_list):\n","        if j == 'NaN':\n","            index.append(i)\n","    \n","    # count the number of NaN/compromised point\n","    p1 = working_list.count('NaN')\n","    # print(p1)\n","    \n","    t = p1 # Total number of missing value\n","    \n","    # Select the min & max from list\n","    # working_list.remove('NaN')\n","    count=0\n","    for index_pos in index:\n","        working_list.pop(index_pos-count)\n","        count+=1\n","    \n","\n","    # find mean of all observed values\n","    mean = np.mean(working_list)\n","\n","    \n","    #find min value\n","    a = min(working_list)\n","    \n","    #find max value\n","    b = max(working_list)\n","    \n","    # Calculate h = (b-a)/t\n","    h = (b-a)/t\n","    \n","    # Calculate the discrete universe U using u = (a + (s-1) x h + a + s x h)/2, s=1,2,3\n","    U = []\n","    for s in range(1,t+1):\n","        u = (a + (s-1) * h + a + s * h)/2\n","        U.append(u)\n","    \n","    # print(U)\n","        \n","    # Calculating the missing values\n","    M = []    \n","    for u in U:\n","        # print(U)\n","        \n","        # Compute the contribution weight (micro) of each observed element x_i\n","        \n","        contribution_weight_list = []\n","        \n","        for i in working_list:\n","            if abs(i-u) <= h:\n","                temp = 1-(abs(i-u)/h)\n","            else:\n","                temp = 0\n","            contribution_weight_list.append(temp)\n","        \n","        # Calculate the sum of x_i to u1:\n","        sum_contribution_weight_list = sum(contribution_weight_list)\n","        # print(sum_contribution_weight_list)\n","        \n","        # Calculate the contribution of an observed data x_i\n","        sum_contribution_observed_data = []\n","        \n","        for num1, num2 in zip(working_list, contribution_weight_list):\n","        \tsum_contribution_observed_data.append(num1 * num2)\n","        \n","        sum_contribution_observed_data = sum(sum_contribution_observed_data)\n","        # print(sum_contribution_observed_data)\n","        \n","        # Calculate the missing values in x_i\n","        if sum_contribution_weight_list == 0:\n","            m = mean\n","        else:\n","            m = sum_contribution_observed_data/sum_contribution_weight_list\n","        \n","        M.append(m)\n","    \n","    # print('The values:',M)\n","    # print('The index position:',index)\n","    return [index,M]"],"metadata":{"id":"j3tVt72psZFb","executionInfo":{"status":"ok","timestamp":1655291172995,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5080,"outputs":[]},{"cell_type":"code","source":["# # # Modified the dataset\n","data = df['RH'].to_list()\n","\n","# # # Determine the outlier for repairing\n","index_outlier = []\n","\n","y = df['label']\n","count_outlier = 0\n","for i, j in enumerate(y):\n","    if j == 0.0:\n","        index_outlier.append(i)\n","        count_outlier+=1\n","    if count_outlier == PERCENTAGE_REPAIRED: break\n","\n","# Determine the compromised data\n","for ind in index_outlier:\n","    data[ind] = 'NaN'\n","\n","# Recover compromised data\n","working_list = data\n","\n","results = FID_repaired(working_list)\n","\n","# print('The recovered values:',results[1])\n","# print('The index position:',results[0])\n","    "],"metadata":{"id":"IBwPX9ejDOGN","executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5081,"outputs":[]},{"cell_type":"code","source":["# # # Update the predicted data into dataset\n","pos = 0\n","for index_pos in results[0]:\n","  df_1 = df.iloc[index_pos]\n","  df_1['RH'] = results[1][pos]\n","  df_1['label'] = 1\n","\n","  df.loc[index_pos] = df_1\n","  pos+=1"],"metadata":{"id":"wywVPakZtkdc","executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5082,"outputs":[]},{"cell_type":"code","source":["# # # Splitting the dataset\n","y = df['label']\n","X = df.drop(['index', 'label'], axis =1)\n","\n","# print(np.count_nonzero(y == 0))\n","\n","# Spliting data\n","x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.3, stratify=y)\n"],"metadata":{"id":"_nJDd_aDxKM1","executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5083,"outputs":[]},{"cell_type":"code","source":["# # # # Random Forest\n","# forest = RandomForestClassifier(n_estimators = 10, random_state = 0)\n","# forest.fit(x_train, y_train)\n","# preds = forest.predict(x_test)\n","\n","\n","# # # Metrics\n","# print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","# print('f1_score: ', round(f1_score(y_test,preds),6))\n","# print('precision_score: ', round(precision_score(y_test,preds),6))\n","# print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))"],"metadata":{"id":"gC5qz7ugDZAZ","executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":5,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5084,"outputs":[]},{"cell_type":"code","source":["# # # # # Autoencoder\n","\n","# x_train = np.asarray(x_train).astype('float32')\n","# x_test = np.asarray(x_test).astype('float32')\n","# y_train = np.asarray(y_train).astype('float32')\n","# y_test = np.asarray(y_test).astype('float32')\n","\n","# # Splitting the for testing and validating dataset\n","# x_val, x_test, y_val, y_test = train_test_split(x_test,y_test, test_size=0.33,stratify=y_test)\n","\n","# class AutoEncoder(Model):\n","#   \"\"\"\n","#   Parameters\n","#   ----------\n","#   output_units: int\n","#     Number of output units\n","  \n","#   code_size: int\n","#     Number of units in bottle neck\n","#   \"\"\"\n","\n","#   def __init__(self, output_units, code_size=8):\n","#     super().__init__()\n","#     self.encoder = Sequential([\n","#       Dense(64, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(32, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(16, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(code_size, activation='relu')\n","#     ])\n","#     self.decoder = Sequential([\n","#       Dense(16, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(32, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(64, activation='relu'),\n","#       Dropout(0.1),\n","#       Dense(output_units, activation='sigmoid')\n","#     ])\n","  \n","#   def call(self, inputs):\n","#     encoded = self.encoder(inputs)\n","#     decoded = self.decoder(encoded)\n","#     return decoded\n","\n","# model = AutoEncoder(output_units=x_train.shape[1])\n","# # configurations of model\n","# model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n","\n","# # simple early stopping\n","# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n","\n","# history = model.fit(\n","#     x_train,\n","#     x_train,\n","#     epochs=50,\n","#     batch_size=128,\n","#     validation_data=(x_val, x_val),\n","#     verbose=0,\n","#     callbacks=[es]\n","# )\n","\n","# def find_threshold(model, x_train_scaled):\n","#   # another method to find threshold\n","#   reconstructions = model.predict(x_train_scaled)\n","#   # provides losses of individual instances\n","#   reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n","\n","#   threshold_2 = np.percentile(reconstruction_errors, 100-OUTLIER_PECENTAGE)\n","#   return threshold_2\n","\n","# def get_predictions(model, x_test_scaled, threshold):\n","#   predictions = model.predict(x_test_scaled)\n","#   # provides losses of individual instances\n","#   errors = tf.keras.losses.msle(predictions, x_test_scaled)\n","#   # 0 = anomaly, 1 = normal\n","#   anomaly_mask = pd.Series(errors) > threshold\n","#   preds = anomaly_mask.map(lambda x: 0.0 if x == True else 1.0)\n","#   return preds\n","\n","# threshold = find_threshold(model, x_train)\n","# preds = get_predictions(model, x_test, threshold)\n","\n","# preds = np.asarray(preds).astype('float32')\n","\n","# #Metrics\n","# print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","# print('f1_score: ', round(f1_score(y_test,preds),6))\n","# print('precision_score: ', round(precision_score(y_test,preds),6))\n","# print('recall_score: ', round(recall_score(y_test,preds),6))\n","# tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","# specificity = tn/(tn+fp)\n","# print('Specificity : ', round(specificity,6))"],"metadata":{"id":"Xtm95dWZRDt6","executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"execution_count":5085,"outputs":[]},{"cell_type":"code","source":["# # # KNeighborsClassifier\n","\n","neigh = KNeighborsClassifier(n_neighbors=5)\n","neigh.fit(x_train, y_train)\n","\n","preds = neigh.predict(x_test)\n","\n","# Metrics\n","print('accuracy_score: ', round((accuracy_score(y_test,preds)*100),2))\n","print('f1_score: ', round(f1_score(y_test,preds),6))\n","print('precision_score: ', round(precision_score(y_test,preds),6))\n","print('recall_score: ', round(recall_score(y_test,preds),6))\n","tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n","specificity = tn/(tn+fp)\n","print('Specificity : ', round(specificity,6))"],"metadata":{"id":"zpQ5XskBH3T1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655291172996,"user_tz":-600,"elapsed":4,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}},"outputId":"0d09b964-d120-4911-bac5-ea10f4200ee5"},"execution_count":5086,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy_score:  97.06\n","f1_score:  0.985075\n","precision_score:  0.970588\n","recall_score:  1.0\n","Specificity :  0.0\n"]}]}]}