{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1530,"status":"ok","timestamp":1655555784464,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"},"user_tz":-600},"id":"VnLMjREJB0lu"},"outputs":[],"source":["# # # Import libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1594,"status":"ok","timestamp":1655555786056,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"},"user_tz":-600},"id":"2YLcNu1_B5xT"},"outputs":[],"source":["# # #  import data\n","df = pd.read_csv('/content/drive/MyDrive/dataset/UNSW_noisy_data/UNSW_noisy_dur_02_1_1.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":401,"status":"ok","timestamp":1655555786453,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"},"user_tz":-600},"id":"Dsr-Z3C8CF1C"},"outputs":[],"source":["# # #  Parameter configurations\n","# SIGMA = 0.5\n","# OUTLIER_PECENTAGE = 1\n","PERCENTAGE_REPAIRED = 1724*1\n","    \n","length = df.shape[0]\n","\n","columns = df.columns.tolist()\n","\n","# Shuffle data\n","df = df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655555786453,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"},"user_tz":-600},"id":"ansqvyloDjVJ"},"outputs":[],"source":["# # # FID for repairing data\n","def FID_repaired(working_list):\n","    # working_list = x1\n","    \n","    index = []\n","    for i, j in enumerate(working_list):\n","        if j == 'NaN':\n","            index.append(i)\n","    \n","    # count the number of NaN/compromised point\n","    p1 = working_list.count('NaN')\n","    # print(p1)\n","    \n","    t = p1 # Total number of missing value\n","    \n","    # Select the min & max from list\n","    # working_list.remove('NaN')\n","    count=0\n","    for index_pos in index:\n","        working_list.pop(index_pos-count)\n","        count+=1\n","    \n","    # find mean of all observed values\n","    mean = np.mean(working_list)\n","    \n","    #find min value\n","    a = min(working_list)\n","    \n","    #find max value\n","    b = max(working_list)\n","    \n","    # Calculate h = (b-a)/t\n","    h = (b-a)/t\n","    \n","    # Calculate the discrete universe U using u = (a + (s-1) x h + a + s x h)/2, s=1,2,3\n","    U = []\n","    for s in range(1,t+1):\n","        u = (a + (s-1) * h + a + s * h)/2\n","        U.append(u)\n","    \n","    # print(U)\n","        \n","    # Calculating the missing values\n","    M = []    \n","    for u in U:\n","        # print(U)\n","        \n","        # Compute the contribution weight (micro) of each observed element x_i\n","        \n","        contribution_weight_list = []\n","        \n","        for i in working_list:\n","            if abs(i-u) <= h:\n","                temp = 1-(abs(i-u)/h)\n","            else:\n","                temp = 0\n","            contribution_weight_list.append(temp)\n","        \n","        # Calculate the sum of x_i to u1:\n","        sum_contribution_weight_list = sum(contribution_weight_list)\n","        # print(sum_contribution_weight_list)\n","        \n","        # Calculate the contribution of an observed data x_i\n","        sum_contribution_observed_data = []\n","        \n","        for num1, num2 in zip(working_list, contribution_weight_list):\n","        \tsum_contribution_observed_data.append(num1 * num2)\n","        \n","        sum_contribution_observed_data = sum(sum_contribution_observed_data)\n","        # print(sum_contribution_observed_data)\n","        \n","        # Calculate the missing values in x_i\n","        if sum_contribution_weight_list == 0:\n","            m = mean\n","        else:\n","            m = sum_contribution_observed_data/sum_contribution_weight_list\n","        \n","        M.append(m)\n","    \n","    # print('The values:',M)\n","    # print('The index position:',index)\n","    return [index,M]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vSCrjBILDxE1","executionInfo":{"status":"ok","timestamp":1655555894592,"user_tz":-600,"elapsed":108142,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"outputs":[],"source":["# # # Repairing data\n","data = df['dur'].to_list()\n","\n","# # # Determine the outlier for repairing\n","index_outlier = []\n","\n","y = df['label2']\n","count_outlier = 0\n","for i, j in enumerate(y):\n","    if j == 0.0:\n","        index_outlier.append(i)\n","        count_outlier+=1\n","    if count_outlier == PERCENTAGE_REPAIRED: break\n","\n","# Determine the compromised data\n","for ind in index_outlier:\n","    data[ind] = 'NaN'\n","\n","# Recover compromised data\n","working_list = data\n","\n","results = FID_repaired(working_list)\n","\n","# print('The recovered values:',results[1])\n","# print('The index position:',results[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"cyntmuUfFG2D","executionInfo":{"status":"ok","timestamp":1655556001763,"user_tz":-600,"elapsed":107190,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"outputs":[],"source":["# # # Update the predicted data into dataset\n","pos = 0\n","for index_pos in results[0]:\n","  df_1 = df.iloc[index_pos]\n","  df_1['dur'] = results[1][pos]\n","  # df_1['label2'] = 1\n","\n","  df.loc[index_pos] = df_1\n","  pos+=1\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"rCX6GicqFLHR","executionInfo":{"status":"ok","timestamp":1655556005462,"user_tz":-600,"elapsed":3717,"user":{"displayName":"Nhung Ngo","userId":"01707313346815136711"}}},"outputs":[],"source":["# # # # Splitting the dataset\n","# y = df['label2']\n","# print(np.count_nonzero(y == 0))\n","# X = df.drop(['index', 'label','label2'], axis =1)\n","# print(np.count_nonzero(y == 0))\n","\n","# # # New noisy dataset\n","df.to_csv('/content/drive/MyDrive/dataset/UNSW_missing_data/UNSW_missing_repaired_dur_01.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"UNSW_outlier_repaired_dataset.ipynb","provenance":[],"mount_file_id":"15lU3y-NnTDj_VpmtX58W4jTHzFF22K3S","authorship_tag":"ABX9TyOBQxlpMOd6Qm88wino8HGB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}